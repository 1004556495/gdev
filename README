#####################################################################
# Gdev: Open-Source GPGPU Runtime and Driver Software
# 
# README
#
# Copyright (C) Shinpei Kato
#
# Nagoya University
# Parallel and Distributed Systems Lab (PDSL)
# http://pdsl.jp
#
# University of California, Santa Cruz
# Systems Research Lab (SRL)
# http://systems.soe.ucsc.edu
#
# All Rights Reserved.
#####################################################################

Gdev is a rich set of open-source GPGPU runtime and driver software.
Currently it supports NVIDIA GPUs but is also portable to other GPUs.
The supported API implementaions include:
1. "Gdev API": A low-level API to manage details of GPUs.
2. "CUDA Driver API": A high-level API adovocated by NVIDIA, which is
   built on top of Gdev API. 
Leveraging Gdev API, you can add your favorite high-level API to Gdev
other than CUDA Driver API. We will support CUDA Runtime API as well.

Gdev provides runtime support in both the device driver and the user-
space library. Runtime support in the device driver is unique to Gdev
while most of existing GPGPU programming frameworks take user-space 
approaches. It allows the OS to manage GPUs as first-class citizens
and execute CUDA programs by itself, using loadable kernel modules.
Gdev's user-space runtime support is also unique in a sense that it 
is available for multiple open-source and proprietary device drivers.
The supported device drivers include:
1. "Nouveau": An open-source driver developed by the Linux community.
2. "PSCNV": An open-source driver developed by PathScale.
3. "NVRM": A proprietary binary driver provided by NVIDIA.

To summarize, Gdev offers the following advantages:
- You have open-source access to GPGPU runtime and driver software.
- You can execute CUDA in the OS using loabable kernel modules.
- You can investigate GPU resource management in research.
- You can enhance OS and user-space runtime support capabilities.
- You can compare device drivers performance under the same runtime.


#####################################################################
# How to download, install, and use Gdev
#####################################################################

Do you want to employ runtime support in the OS?
 -> See docs/README.gdev

Do you want to use user-space runtime with Nouveau?
 -> See docs/README.nouveau

Do you want to use user-space runtime with PSCNV?
 -> See docs/README.pscnv

Do you want to use user-space runtime with NVRM (NVIDIA Driver)?
 -> See docs/README.nvrm


#####################################################################
# Related research papers 
#####################################################################

S. Kato, M. McThrow, C. Maltzahn, and S. Brandt. "Gdev: First-Class
GPU Resource Management in the Operating System", In Proceedings of 
the 2012 USENIX Annual Technical Conference (USENIX ATC'12), 2012.

Y. Abe, H. Sasaki, M. Peres, K. Inoue, K. Murakami, and S. Kato. 
"Power and Performance Analysis of GPU-Accelerated Systems", In 
Proceedings of the 5th UESNIX Workshop on Power-Aware Computing and
Systems (HotPower'12) , 2012.

S. Kato. "Implementing Open-Source CUDA Runtime", In Proceedings of
the 54th Programming Symposium, Jan, 2013.

S. Kato, J. Aumiller, and S. Brandt. "Zero-Copy I/O Processing for 
Low-Latency GPU Computing", In Proceedings of the 4th ACM/IEEE 
International Conference on Cyber-Physical Systems (ICCPS'13), 2013.


#####################################################################
# Reclocking the GPU
#####################################################################

NVIDIA's graphics cards are set very low clocks by default. To get
performance, you need to reclock your card at the maximum level.
How? Be root first, and then echo 3 to the following file:

echo 3 > /sys/class/drm/card0/device/performance_level

You can downclock your card by echoing 0 to the same file, i.e.,

echo 0 > /sys/class/drm/card0/device/performance_level

There are middleground levels 1 and 2, too. Note that Reclocking
is not completely supported by the open-source solution yet.
There are still some performance levels missing, and hence you may
not get as high performance as the blob. If you really need the same
level of performance as the blob, you can run some long-running
CUDA program with the blob, and do kexec -f your kernel before the
program is finished. Then the clock remains at the maximum level.


#####################################################################
# Benchmarks and Applications
#####################################################################

Gdev currently supports CUDA Driver API, while many CUDA programs you
may find today are written using CUDA Runtime API. As mentioned above,
you can use Ocelot to translate CUDA Runtime API to CUDA Driver API,
but we also provide some benchmarks and applications that are written
using CUDA Driver API so that you can quickly start using Gdev.
Try downloading the following:
git@github.com:shinpei0208/gdev-app.git
git@github.com:shinpei0208/gdev-bench.git


#####################################################################
# Contributors
#####################################################################

 Yuki ABE, Kyushu University
 Jason AUMILLER, University of California at Santa Cruz
 Takuya AZUMI, Ritsumeikan University
 Masato EDAHIRO, Nagoya University
 Yusuke FUJII, Ritsumeikan University
 Tsuyoshi HAMADA, Nagasaki University
 Masaaki IWATA, AXE Inc.
 Shinpei KATO, Nagoya University (Maintainer)
 Marcin KOSCIELNICKI, University of Warsaw
 Michael MCTHROW, University of California at Santa Cruz
 Martin PERES, University of Bordeaux
 Hiroshi SASAKI, Kyushu University
 Yusuke SUZUKI, Keio University
 Kaibo WANG, Ohio State University
 Hiroshi YAMADA, Tokyo University of Agriculture and Technology
